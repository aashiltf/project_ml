{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lightgbm\n",
    "import matplotlib.pylab as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserting all features from test into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       average_income_per_grunnkrets  distance_store_busstop  area_grunnkrets\n",
      "0                           561700.0              585.354489         0.155779\n",
      "1                           555720.0              138.798366         0.264278\n",
      "2                           495900.0               41.099519         0.160152\n",
      "3                           521240.0               56.693017         0.095029\n",
      "4                           585360.0              229.077959         0.251070\n",
      "...                              ...                     ...              ...\n",
      "12854                       505640.0              150.004125         0.291337\n",
      "12855                       396640.0              322.573926         0.137188\n",
      "12856                       549120.0              174.851316         0.123431\n",
      "12857                       498660.0              121.372663         0.034857\n",
      "12858                       579780.0              189.983143         0.204915\n",
      "\n",
      "[12859 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "folder_train = 'features_train_csv'\n",
    "\n",
    "features_train = pd.read_csv(os.path.join(folder_train, os.listdir(folder_train)[0]))\n",
    "for i in range(1,len(os.listdir(folder_train))):\n",
    "    f = os.path.join(folder_train,os.listdir(folder_train)[i])\n",
    "    if os.path.isfile(f):\n",
    "        features_train = pd.concat([features_train, pd.read_csv(f)], axis=1)\n",
    "print(features_train)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat for test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      average_income_per_grunnkrets  distance_store_busstop  area_grunnkrets\n",
      "0                          551600.0               25.630061         0.057027\n",
      "1                          531240.0              111.736189         0.165993\n",
      "2                          523300.0              404.825119         0.236628\n",
      "3                          591380.0              317.141300         0.983436\n",
      "4                          594020.0              101.273354         0.449502\n",
      "...                             ...                     ...              ...\n",
      "8572                       560700.0              364.034347         1.708924\n",
      "8573                       593340.0              228.923169         0.310575\n",
      "8574                       629100.0              136.232163         1.627789\n",
      "8575                       590100.0              129.203732         1.103012\n",
      "8576                       529980.0              212.494198         1.677433\n",
      "\n",
      "[8577 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "folder_test = 'features_test_csv'\n",
    "\n",
    "features_test = pd.read_csv(os.path.join(folder_test, os.listdir(folder_test)[0]))\n",
    "for i in range(1,len(os.listdir(folder_test))):\n",
    "    f = os.path.join(folder_test,os.listdir(folder_test)[i])\n",
    "    if os.path.isfile(f):\n",
    "        features_test = pd.concat([features_test, pd.read_csv(f)], axis=1)\n",
    "print(features_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target train data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train = pd.read_csv(\"data/stores_train.csv\")\n",
    "target_train = target_train['revenue'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate independent and dependent variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Light GBM model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify parametrs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model = lightgbm.LGBMRegressor(\n",
    "    num_leaves=4,\n",
    "    max_depth=5, \n",
    "    random_state=42, \n",
    "    silent=True, \n",
    "    metric='mse',\n",
    "    n_jobs=4, \n",
    "    n_estimators=1000,\n",
    "    colsample_bytree=0.95,\n",
    "    subsample=0.9,\n",
    "    learning_rate=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12859\n",
      "[[17.998]\n",
      " [23.828]\n",
      " [16.099]\n",
      " ...\n",
      " [38.225]\n",
      " [ 3.642]\n",
      " [ 2.328]]\n",
      "<class 'numpy.ndarray'>\n",
      "12859\n"
     ]
    }
   ],
   "source": [
    "#print(features_train)\n",
    "#print(type(features_train))\n",
    "print(len(features_train))\n",
    "print(target_train)\n",
    "print(type(target_train))\n",
    "target_train = target_train\n",
    "print(len(target_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model.fit(features_train, target_train)\n",
    "lgbm_preditions = lgbm_model.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.66628177 10.50847669  4.97765824 ... 12.8724819  10.19661478\n",
      " 11.01592438]\n"
     ]
    }
   ],
   "source": [
    "print(lgbm_preditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
