{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lightgbm\n",
    "import matplotlib.pylab as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserting all features from test into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       plaace_h_1  plaace_h_2  plaace_h_3  plaace_h_4  features\n",
      "0               1           1           1           0         0\n",
      "1               1           1           1           0         0\n",
      "2               1           1           1           0         0\n",
      "3               1           1           1           0         0\n",
      "4               1           1           1           0         0\n",
      "...           ...         ...         ...         ...       ...\n",
      "12854           2           8          11           2        90\n",
      "12855           2           8          11           2        90\n",
      "12856           2           8          11           2        90\n",
      "12857           2           8          11           2        90\n",
      "12858           2           8          11           2        90\n",
      "\n",
      "[12859 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "folder_train = '../features_train_in_use'\n",
    "\n",
    "features_train = pd.read_csv(os.path.join(folder_train, os.listdir(folder_train)[0]))\n",
    "for i in range(1,len(os.listdir(folder_train))):\n",
    "    f = os.path.join(folder_train,os.listdir(folder_train)[i])\n",
    "    if os.path.isfile(f):\n",
    "        features_train = pd.concat([features_train, pd.read_csv(f)], axis=1)\n",
    "print(features_train)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat for test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      plaace_h_1  plaace_h_2  plaace_h_3  plaace_h_4  features\n",
      "0              1           1           1           0         0\n",
      "1              1           1           1           0         0\n",
      "2              1           1           1           0         0\n",
      "3              1           1           1           0         0\n",
      "4              1           1           1           0         0\n",
      "...          ...         ...         ...         ...       ...\n",
      "8572           2           8          11           2        85\n",
      "8573           2           8          11           2        85\n",
      "8574           2           8          11           2        85\n",
      "8575           2           8          11           2        85\n",
      "8576           2           8          11           2        85\n",
      "\n",
      "[8577 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "folder_test = '../features_test_in_use'\n",
    "\n",
    "features_test = pd.read_csv(os.path.join(folder_test, os.listdir(folder_test)[0]))\n",
    "for i in range(1,len(os.listdir(folder_test))):\n",
    "    f = os.path.join(folder_test,os.listdir(folder_test)[i])\n",
    "    if os.path.isfile(f):\n",
    "        features_test = pd.concat([features_test, pd.read_csv(f)], axis=1)\n",
    "print(features_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target train data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train = pd.read_csv(\"../data/stores_train.csv\")\n",
    "target_train = target_train['revenue'].values\n",
    "\n",
    "#log transform\n",
    "target_train = np.log1p(target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Light GBM model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model = lightgbm.LGBMRegressor(\n",
    "    num_leaves=4,\n",
    "    max_depth=5, \n",
    "    random_state=42, \n",
    "    silent=True, \n",
    "    metric='mse',\n",
    "    n_jobs=4, \n",
    "    n_estimators=1000,\n",
    "    colsample_bytree=0.95,\n",
    "    subsample=0.9,\n",
    "    learning_rate=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12859\n",
      "[2.94433371 3.21197205 2.83901998 ... 3.6693143  1.53514531 1.20237152]\n",
      "<class 'numpy.ndarray'>\n",
      "12859\n"
     ]
    }
   ],
   "source": [
    "#print(features_train)\n",
    "#print(type(features_train))\n",
    "print(len(features_train))\n",
    "print(target_train)\n",
    "print(type(target_train))\n",
    "target_train = target_train\n",
    "print(len(target_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\lightgbm\\sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    }
   ],
   "source": [
    "lgbm_model.fit(features_train, target_train)\n",
    "lgbm_predictions = lgbm_model.predict(features_test)\n",
    "\n",
    "#Undo log transform\n",
    "lgbm_predictions = np.expm1(lgbm_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.92478661 6.92478661 6.92478661 ... 3.25299387 3.25299387 3.25299387]\n"
     ]
    }
   ],
   "source": [
    "print(lgbm_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_test = pd.read_csv(\"../data/stores_test.csv\")\n",
    "stores_test_id = stores_test['store_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              id  predicted\n",
      "0     914206820-914239427-717245   6.924787\n",
      "1     916789157-916823770-824309   6.924787\n",
      "2       913341082-977479363-2948   6.924787\n",
      "3      889682582-889697172-28720   6.924787\n",
      "4     997991699-998006945-417222   6.924787\n",
      "...                          ...        ...\n",
      "8572  917323003-917383529-844309   3.252994\n",
      "8573  917353379-917411824-845904   3.252994\n",
      "8574  917072302-917089248-833647   3.252994\n",
      "8575  916960557-916993161-829908   3.252994\n",
      "8576   987280891-972040746-45320   3.252994\n",
      "\n",
      "[8577 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "predictions = pd.DataFrame()\n",
    "\n",
    "predictions['id'] = stores_test_id\n",
    "predictions['predicted'] = lgbm_predictions\n",
    "predictions.to_csv(\"../predictions/lightGBM7.csv\", index=False)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\lightgbm\\sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A couple of RMSLE scores computed over the train set\n",
      "Perfect prediction: 0.0000\n",
      "Score: 0.3467\n",
      "Score:  0.3466855773904046\n"
     ]
    }
   ],
   "source": [
    "def rmsle(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes the Root Mean Squared Logarithmic Error \n",
    "    \n",
    "    Args:\n",
    "        y_true (np.array): n-dimensional vector of ground-truth values \n",
    "        y_pred (np.array): n-dimensional vecotr of predicted values \n",
    "    \n",
    "    Returns:\n",
    "        A scalar float with the rmsle value \n",
    "    \n",
    "    Note: You can alternatively use sklearn and just do: \n",
    "        `sklearn.metrics.mean_squared_log_error(y_true, y_pred) ** 0.5`\n",
    "    \"\"\"\n",
    "    assert (y_true >= 0).all(), 'Received negative y_true values'\n",
    "    assert (y_pred >= 0).all(), 'Received negative y_pred values'\n",
    "    assert y_true.shape == y_pred.shape, 'y_true and y_pred have different shapes'\n",
    "    y_true_log1p = np.log1p(y_true)  # log(1 + y_true)\n",
    "    y_pred_log1p = np.log1p(y_pred)  # log(1 + y_pred)\n",
    "    return np.sqrt(np.mean(np.square(y_pred_log1p - y_true_log1p)))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_train, target_train, test_size=0.2, random_state=42)\n",
    "\n",
    "lgbm_model2 = lightgbm.LGBMRegressor(\n",
    "    num_leaves=4,\n",
    "    max_depth=5, \n",
    "    random_state=42, \n",
    "    silent=True, \n",
    "    metric='mse',\n",
    "    n_jobs=4, \n",
    "    n_estimators=1000,\n",
    "    colsample_bytree=0.95,\n",
    "    subsample=0.9,\n",
    "    learning_rate=0.05\n",
    ")\n",
    "\n",
    "lgbm_model2.fit(X_train, y_train)\n",
    "y_pred = lgbm_model2.predict(X_test)\n",
    "# Calculate rmsle for a few example predictions \n",
    "y_true = y_test\n",
    "n = len(features_train)\n",
    "print('A couple of RMSLE scores computed over the train set')\n",
    "print(f'Perfect prediction: {rmsle(y_true, y_true):.4f}')\n",
    "print(f'Score: {rmsle(y_true, y_pred):.4f}')\n",
    "\n",
    "print(\"Score: \",sklearn.metrics.mean_squared_log_error(y_true, y_pred) ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
